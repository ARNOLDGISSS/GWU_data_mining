## Section 09: Matrix factorization

Matrix factorization enables us to represent sparse or high-dimensional data 
sets and high cardinality features with a small number of dense of numeric 
features suitable for modeling and visualization.

#### Class Notes 

* Basic PCA examples

  * [One component with back-projection](../02_analytical_data_prep/src/py_part_2_feature_extraction.ipynb)
  
  * [Iris data with visualization](src/py_part_9_iris_pca.ipynb)

#### Supplementary References

* [Generalized Low Rank Models (GLRM) with H2O](http://docs.h2o.ai/h2o-tutorials/latest-stable/tutorials/glrm/glrm-tutorial.html)

* [LibFM for Factorization Machines](http://libfm.org/)

***

* [*Elements of Statistical Learning*](http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf)</br>
Sections 14.5 - 14.6, 14.8

* [*Pattern Recognition in Machine Learning*](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)</br>
Chapter 12

* [Learning the Parts of Objects by Nonnegative Matrix Factorization](https://www.cs.princeton.edu/courses/archive/spring12/cos424/pdf/lee-seung.pdf)</br>
by Daniel D. Lee & H. Sebastian Seung

* [Generalized Low Rank Models](http://www.web.stanford.edu/~boyd/papers/pdf/glrm.pdf)</br>
by Madeleine Udell, Corinne Horn, Reza Zadeh, and Stephen Boyd

* [Factorization Machines](http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf)</br>
by Steffen Rendle

